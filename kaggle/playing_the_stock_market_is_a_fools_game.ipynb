{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# pip install optuna captum"
   ],
   "metadata": {
    "collapsed": true,
    "id": "4DiDpU9JozQD",
    "ExecuteTime": {
     "end_time": "2025-03-26T14:52:50.581767Z",
     "start_time": "2025-03-26T14:52:50.579850Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "id": "Ufxefb35onp-",
    "ExecuteTime": {
     "end_time": "2025-03-26T14:52:50.600622Z",
     "start_time": "2025-03-26T14:52:50.596572Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WITosy8ThpO3",
    "ExecuteTime": {
     "end_time": "2025-03-26T14:52:50.614663Z",
     "start_time": "2025-03-26T14:52:50.612222Z"
    }
   },
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"加载训练数据并返回DataFrame和日期列\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"原始数据维度: {df.shape}\")  # 输出数据的行数和列数（如：(442, 4000)）\n",
    "\n",
    "    # 转换日期列并验证\n",
    "    dates = pd.to_datetime(df.columns[1:], format='%d/%m/%Y')\n",
    "    print(f\"日期列数量: {len(dates)}\")  # 输出日期列的数量（如：4000天）\n",
    "\n",
    "    return df, dates"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_data(df, window_size=10):\n",
    "    scaled_data = {}\n",
    "    for company_id in df['ID'].unique():\n",
    "        # 提取单个公司的数据（跳过ID列）\n",
    "        company_series = df[df['ID'] == company_id].iloc[:, 1:].values.astype(float)\n",
    "        # 标准化（保持二维）\n",
    "        scaler = StandardScaler()\n",
    "        scaled = scaler.fit_transform(company_series.reshape(-1, 1))  # 形状为 (n_samples, 1)\n",
    "        scaled_data[company_id] = {\n",
    "            'data': scaled,\n",
    "            'scaler': scaler\n",
    "        }\n",
    "        # print(f\"公司 {company_id} 标准化后的数据维度: {scaled.shape}\")\n",
    "    # print(scaled_data)\n",
    "    print(f\"标准化后的数据维度: {len(scaled_data)}\")  # 输出公司数\n",
    "    return scaled_data"
   ],
   "metadata": {
    "id": "ns_Bk0M7i7Ov",
    "ExecuteTime": {
     "end_time": "2025-03-26T14:52:50.627801Z",
     "start_time": "2025-03-26T14:52:50.625276Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# =====================================================================================\n",
    "# 2. 模型定义\n",
    "# =====================================================================================\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM模型实现\"\"\"\n",
    "    def __init__(self, input_dim=1, hidden_dim=32, num_layers=2, output_dim=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM层\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隐藏状态\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        # LSTM前向传播\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # 取最后一个时间步的输出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "metadata": {
    "id": "G4dBJ16Cpz_y",
    "ExecuteTime": {
     "end_time": "2025-03-26T14:52:50.638599Z",
     "start_time": "2025-03-26T14:52:50.636005Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# =====================================================================================\n",
    "# 3. 数据集与数据加载器\n",
    "# =====================================================================================\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, window_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(0, len(self.data) - self.window_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.data[idx:idx + self.window_size]  # 形状为 (window_size, 1)\n",
    "        target = self.data[idx + self.window_size, 0]  # 标量\n",
    "\n",
    "        # 转换为张量\n",
    "        features = torch.tensor(features, dtype=torch.float)  # 形状为 (window_size, 1)\n",
    "        target = torch.tensor([target], dtype=torch.float)  # 包裹成 [scalar] 形状\n",
    "\n",
    "        return features, target"
   ],
   "metadata": {
    "id": "JnvcuFwkp2XD",
    "ExecuteTime": {
     "end_time": "2025-03-26T14:52:50.648513Z",
     "start_time": "2025-03-26T14:52:50.646143Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# =====================================================================================\n",
    "# 4. 训练与验证函数\n",
    "# =====================================================================================\n",
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"模型训练函数\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n"
   ],
   "metadata": {
    "id": "FV98TWo7p4Gr",
    "ExecuteTime": {
     "end_time": "2025-03-26T14:52:50.659401Z",
     "start_time": "2025-03-26T14:52:50.657153Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "def validate_model(model, dataloader, criterion, device):\n",
    "    \"\"\"模型验证函数\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y.view(-1, 1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n"
   ],
   "metadata": {
    "id": "dlp6gVGlp6N9",
    "ExecuteTime": {
     "end_time": "2025-03-26T14:52:50.670036Z",
     "start_time": "2025-03-26T14:52:50.667801Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "id": "ixXaEfWjp8gl",
    "ExecuteTime": {
     "end_time": "2025-03-26T14:52:50.682962Z",
     "start_time": "2025-03-26T14:52:50.677907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "# =====================================================================================\n",
    "# 5. Optuna超参数优化\n",
    "# =====================================================================================\n",
    "import time\n",
    "def objective(trial, window_size, train_datasets, val_datasets):\n",
    "    # 超参数搜索空间\n",
    "    best_model_state = None  # ✅ 确保变量在函数内总是有值\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 16, 64)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    patience = trial.suggest_int(\"patience\", 3, 10)\n",
    "\n",
    "    # init model\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "    model = LSTMModel(input_dim=1, hidden_dim=hidden_dim, num_layers=num_layers).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loaders = [DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "                     for dataset in train_datasets]\n",
    "    val_loaders = [DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "                   for dataset in val_datasets]\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(10):  # 减少总epoch数\n",
    "        model.train() # train 的很快\n",
    "        start_time = time.time()\n",
    "\n",
    "        \"\"\"\n",
    "        下面这个部分是最慢的\n",
    "        \"\"\"\n",
    "        for loader in train_loaders:\n",
    "            for X, y in loader:\n",
    "                # X = X.unsqueeze(-1).to(device)  # 确保形状 (B × window_size × 1)\n",
    "                X = X.to(device, non_blocking=True)  # 确保X的形状为 (batch_size × window_size × 1)\n",
    "                # print(\"X.shape is \", X.shape)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                # y = y.squeeze(-1)  # 现在再去掉多余维度，确保形状一致\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        end_time = time.time()\n",
    "\n",
    "\n",
    "        print(f\"epoch_{epoch}遍历dataloader用时{(end_time-start_time)}\" )\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for loader in val_loaders:\n",
    "                for X, y in loader:\n",
    "                    X = X.to(device, non_blocking=True)\n",
    "                    # X = X.unsqueeze(-1).to(device)\n",
    "                    y = y.to(device, non_blocking=True)\n",
    "                    outputs = model(X)\n",
    "                    val_loss += criterion(outputs, y).item()\n",
    "        avg_val_loss = val_loss / len(val_loaders)\n",
    "        print(f\"epoch_{epoch}eval后遍历dataloader用时{(time.time()-end_time)}\" )\n",
    "\n",
    "        # 6. 更新最优模型\n",
    "        if avg_val_loss < best_loss:\n",
    "            print(f\"有更新, 最新的loss是{avg_val_loss}\")\n",
    "            best_loss = avg_val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())  # ✅ 彻底复制参数，避免 shallow copy 问题\n",
    "            trial.set_user_attr(\"best_model\", best_model_state)\n",
    "            print(\"是否真的存进去了: \", \"best_model\" in trial.study.user_attrs)\n",
    "            # 手动保存到文件，防止 Optuna 多进程问题\n",
    "            torch.save(best_model_state, \"best_model.pth\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                break  # 早停\n",
    "\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # 7. 存储最优模型到 Optuna\n",
    "    if best_model_state is not None:\n",
    "        trial.set_user_attr(\"best_model\", best_model_state)  # ✅ 再次确保写入 Optuna\n",
    "\n",
    "    return best_loss"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "collapsed": true,
    "id": "vp_MKzg_qBd2",
    "outputId": "511b7054-9236-4dac-880c-52a88c275cb1",
    "ExecuteTime": {
     "end_time": "2025-03-26T16:50:08.621466Z",
     "start_time": "2025-03-26T14:52:50.691356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =====================================================================================\n",
    "# 6. 主函数\n",
    "# =====================================================================================\n",
    "\n",
    "# 1. 加载数据\n",
    "df, dates = load_data('playing-the-stock-market-is-a-fools-game/train.csv')\n",
    "scaled_data = preprocess_data(df, window_size=10)\n",
    "\n",
    "# 2. 超参数设置\n",
    "window_size = 10\n",
    "test_ratio = 0.2\n",
    "\n",
    "# 3. 数据准备\n",
    "train_datasets = []\n",
    "val_datasets = []\n",
    "for company_id in scaled_data.keys():\n",
    "    data = scaled_data[company_id]['data']\n",
    "    # print(data)\n",
    "    split = int(len(data) * (1 - test_ratio))\n",
    "\n",
    "    # 确保训练集和验证集至少有 window_size 的数据\n",
    "    train_data = data[:split]\n",
    "    val_data = data[max(split - window_size, 0):]  # 确保验证集长度足够\n",
    "\n",
    "    train_datasets.append(TimeSeriesDataset(train_data, window_size))\n",
    "    val_datasets.append(TimeSeriesDataset(val_data, window_size))\n",
    "\n",
    "# 4. Optuna优化\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, window_size, train_datasets, val_datasets),\n",
    "              n_trials=20)\n",
    "\n",
    "# 5. 使用最佳模型预测\n",
    "best_params = study.best_params\n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "best_model = LSTMModel(\n",
    "    input_dim=1,\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    num_layers=best_params['num_layers']\n",
    ").to(device)\n",
    "try:\n",
    "    best_model.load_state_dict(study.user_attrs['best_model'])\n",
    "except:\n",
    "    best_model_state = torch.load(\"best_model.pth\")\n",
    "\n",
    "# 6. 预测\n",
    "submission = pd.read_csv('playing-the-stock-market-is-a-fools-game/sample_submission.csv')\n",
    "for idx, row in submission.iterrows():\n",
    "    company_id = row['ID']\n",
    "    # 获取标准化后的数据\n",
    "    company_info = scaled_data[company_id]\n",
    "    last_window = company_info['data'][-window_size:].reshape(1, window_size, 1)\n",
    "    # 预测\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor(last_window, dtype=torch.float).to(device)\n",
    "        pred = best_model(input_tensor)\n",
    "    # 反标准化\n",
    "    pred_value = company_info['scaler'].inverse_transform(pred.cpu().numpy())[0][0]\n",
    "    submission.at[idx, 'value'] = pred_value\n",
    "\n",
    "# 7. 保存结果\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# 8. 模型解释（可选）\n",
    "# 使用Captum分析特征重要性\n",
    "inputs = torch.tensor(last_window, dtype=torch.float32, requires_grad=True).to(device)\n",
    "ig = IntegratedGradients(best_model)\n",
    "attributions, delta = ig.attribute(inputs, target=0, return_convergence_delta=True)\n",
    "# 绘制特征重要性图\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(window_size), attributions[0,:,0].cpu().detach().numpy())\n",
    "plt.title('Feature Importance (Last Window)')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Attribution Score')\n",
    "plt.savefig('feature_importance.png')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据维度: (442, 3022)\n",
      "日期列数量: 3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:52:50,862] A new study created in memory with name: no-name-09545f94-862d-4761-a1ee-951d6bd31e45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准化后的数据维度: 442\n",
      "epoch_0遍历dataloader用时54.76955795288086\n",
      "epoch_0eval后遍历dataloader用时6.445476055145264\n",
      "epoch_1遍历dataloader用时56.347148180007935\n",
      "epoch_1eval后遍历dataloader用时6.295850992202759\n",
      "epoch_2遍历dataloader用时57.66811919212341\n",
      "epoch_2eval后遍历dataloader用时6.6984968185424805\n",
      "epoch_3遍历dataloader用时49.112061977386475\n",
      "epoch_3eval后遍历dataloader用时6.256008863449097\n",
      "epoch_4遍历dataloader用时61.128135204315186\n",
      "epoch_4eval后遍历dataloader用时6.172161817550659\n",
      "epoch_5遍历dataloader用时60.44142174720764\n",
      "epoch_5eval后遍历dataloader用时6.110482215881348\n",
      "epoch_6遍历dataloader用时60.929561138153076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:00:15,508] Trial 0 finished with value: inf and parameters: {'optimizer': 'SGD', 'lr': 4.0170994388202094e-05, 'hidden_dim': 52, 'batch_size': 46, 'num_layers': 1, 'patience': 7}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_6eval后遍历dataloader用时6.2581870555877686\n",
      "epoch_0遍历dataloader用时45.7811758518219\n",
      "epoch_0eval后遍历dataloader用时6.494537115097046\n",
      "epoch_1遍历dataloader用时46.29562997817993\n",
      "epoch_1eval后遍历dataloader用时6.669595956802368\n",
      "epoch_2遍历dataloader用时45.60125803947449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:02:53,008] Trial 1 finished with value: inf and parameters: {'optimizer': 'RMSprop', 'lr': 0.0022108900834360307, 'hidden_dim': 56, 'batch_size': 42, 'num_layers': 1, 'patience': 3}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_2eval后遍历dataloader用时6.648874998092651\n",
      "epoch_0遍历dataloader用时43.81949496269226\n",
      "epoch_0eval后遍历dataloader用时5.066152811050415\n",
      "epoch_1遍历dataloader用时42.43637490272522\n",
      "epoch_1eval后遍历dataloader用时4.924914121627808\n",
      "epoch_2遍历dataloader用时42.96998906135559\n",
      "epoch_2eval后遍历dataloader用时5.0113160610198975\n",
      "epoch_3遍历dataloader用时42.655539989471436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:06:04,631] Trial 2 finished with value: inf and parameters: {'optimizer': 'Adam', 'lr': 1.5861716085623252e-05, 'hidden_dim': 17, 'batch_size': 63, 'num_layers': 2, 'patience': 4}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_3eval后遍历dataloader用时4.730066299438477\n",
      "epoch_0遍历dataloader用时24.059099912643433\n",
      "epoch_0eval后遍历dataloader用时5.060368061065674\n",
      "epoch_1遍历dataloader用时24.097944736480713\n",
      "epoch_1eval后遍历dataloader用时4.871546268463135\n",
      "epoch_2遍历dataloader用时23.32019877433777\n",
      "epoch_2eval后遍历dataloader用时5.006309270858765\n",
      "epoch_3遍历dataloader用时23.97316813468933\n",
      "epoch_3eval后遍历dataloader用时5.021723031997681\n",
      "epoch_4遍历dataloader用时23.65767502784729\n",
      "epoch_4eval后遍历dataloader用时4.679748058319092\n",
      "epoch_5遍历dataloader用时23.872839212417603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:08:57,110] Trial 3 finished with value: inf and parameters: {'optimizer': 'SGD', 'lr': 0.00010153867394436566, 'hidden_dim': 29, 'batch_size': 56, 'num_layers': 1, 'patience': 6}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_5eval后遍历dataloader用时4.851353883743286\n",
      "epoch_0遍历dataloader用时86.9790871143341\n",
      "epoch_0eval后遍历dataloader用时10.939167976379395\n",
      "epoch_1遍历dataloader用时83.34571504592896\n",
      "epoch_1eval后遍历dataloader用时10.792274236679077\n",
      "epoch_2遍历dataloader用时83.51980066299438\n",
      "epoch_2eval后遍历dataloader用时10.286180257797241\n",
      "epoch_3遍历dataloader用时83.56800770759583\n",
      "epoch_3eval后遍历dataloader用时10.675333976745605\n",
      "epoch_4遍历dataloader用时83.73841500282288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:16:51,661] Trial 4 finished with value: inf and parameters: {'optimizer': 'RMSprop', 'lr': 0.026349758194141946, 'hidden_dim': 63, 'batch_size': 27, 'num_layers': 2, 'patience': 5}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_4eval后遍历dataloader用时10.696651220321655\n",
      "epoch_0遍历dataloader用时86.44040703773499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keqinpeng/miniconda3/envs/kaggle/lib/python3.11/site-packages/optuna/pruners/_percentile.py:21: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmin(values)\n",
      "[I 2025-03-26 15:18:27,508] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0eval后遍历dataloader用时9.394794940948486\n",
      "epoch_0遍历dataloader用时39.45577096939087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:19:12,680] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0eval后遍历dataloader用时5.709971904754639\n",
      "epoch_0遍历dataloader用时38.50478267669678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:19:57,038] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0eval后遍历dataloader用时5.846987009048462\n",
      "epoch_0遍历dataloader用时62.231428146362305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:21:06,163] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0eval后遍历dataloader用时6.8852620124816895\n",
      "epoch_0遍历dataloader用时96.6698203086853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:22:56,830] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0eval后遍历dataloader用时13.99090576171875\n",
      "epoch_0遍历dataloader用时98.32851719856262\n",
      "epoch_0eval后遍历dataloader用时9.185971975326538\n",
      "有更新, 最新的loss是39.47191935893974\n",
      "是否真的存进去了:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keqinpeng/miniconda3/envs/kaggle/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_1遍历dataloader用时95.30725407600403\n",
      "epoch_1eval后遍历dataloader用时8.98131513595581\n",
      "有更新, 最新的loss是39.463109386469576\n",
      "是否真的存进去了:  False\n",
      "epoch_2遍历dataloader用时99.91632199287415\n",
      "epoch_2eval后遍历dataloader用时9.11792516708374\n",
      "有更新, 最新的loss是39.455788599571626\n",
      "是否真的存进去了:  False\n",
      "epoch_3遍历dataloader用时100.58245587348938\n",
      "epoch_3eval后遍历dataloader用时9.141499996185303\n",
      "有更新, 最新的loss是39.45269549797327\n",
      "是否真的存进去了:  False\n",
      "epoch_4遍历dataloader用时100.86738514900208\n",
      "epoch_4eval后遍历dataloader用时9.214329957962036\n",
      "有更新, 最新的loss是39.44947799027168\n",
      "是否真的存进去了:  False\n",
      "epoch_5遍历dataloader用时100.6422438621521\n",
      "epoch_5eval后遍历dataloader用时9.122031927108765\n",
      "有更新, 最新的loss是39.44686834101999\n",
      "是否真的存进去了:  False\n",
      "epoch_6遍历dataloader用时96.8618266582489\n",
      "epoch_6eval后遍历dataloader用时9.030955076217651\n",
      "有更新, 最新的loss是39.44508024536882\n",
      "是否真的存进去了:  False\n",
      "epoch_7遍历dataloader用时94.69858503341675\n",
      "epoch_7eval后遍历dataloader用时9.029591083526611\n",
      "有更新, 最新的loss是39.44395783791378\n",
      "是否真的存进去了:  False\n",
      "epoch_8遍历dataloader用时94.85589098930359\n",
      "epoch_8eval后遍历dataloader用时8.943878173828125\n",
      "有更新, 最新的loss是39.44296892294113\n",
      "是否真的存进去了:  False\n",
      "epoch_9遍历dataloader用时91.32006788253784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:40:41,194] Trial 10 finished with value: 39.442232110921076 and parameters: {'optimizer': 'SGD', 'lr': 9.750039776480734e-05, 'hidden_dim': 44, 'batch_size': 29, 'num_layers': 1, 'patience': 10}. Best is trial 10 with value: 39.442232110921076.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_9eval后遍历dataloader用时9.149559020996094\n",
      "有更新, 最新的loss是39.442232110921076\n",
      "是否真的存进去了:  False\n",
      "epoch_0遍历dataloader用时39.43452429771423\n",
      "epoch_0eval后遍历dataloader用时7.964365720748901\n",
      "有更新, 最新的loss是33.8136470156903\n",
      "是否真的存进去了:  False\n",
      "epoch_1遍历dataloader用时40.63692903518677\n",
      "epoch_1eval后遍历dataloader用时8.22617793083191\n",
      "有更新, 最新的loss是33.802740036863916\n",
      "是否真的存进去了:  False\n",
      "epoch_2遍历dataloader用时42.17330718040466\n",
      "epoch_2eval后遍历dataloader用时7.812669992446899\n",
      "有更新, 最新的loss是33.795537235367014\n",
      "是否真的存进去了:  False\n",
      "epoch_3遍历dataloader用时38.57965683937073\n",
      "epoch_3eval后遍历dataloader用时8.458317041397095\n",
      "有更新, 最新的loss是33.79061581243706\n",
      "是否真的存进去了:  False\n",
      "epoch_4遍历dataloader用时38.85285663604736\n",
      "epoch_4eval后遍历dataloader用时7.463795185089111\n",
      "有更新, 最新的loss是33.786859151582775\n",
      "是否真的存进去了:  False\n",
      "epoch_5遍历dataloader用时38.91523504257202\n",
      "epoch_5eval后遍历dataloader用时8.034060955047607\n",
      "有更新, 最新的loss是33.78443003798165\n",
      "是否真的存进去了:  False\n",
      "epoch_6遍历dataloader用时39.89473795890808\n",
      "epoch_6eval后遍历dataloader用时7.468756198883057\n",
      "有更新, 最新的loss是33.78241820432819\n",
      "是否真的存进去了:  False\n",
      "epoch_7遍历dataloader用时38.92367219924927\n",
      "epoch_7eval后遍历dataloader用时7.9833149909973145\n",
      "有更新, 最新的loss是33.78075611859779\n",
      "是否真的存进去了:  False\n",
      "epoch_8遍历dataloader用时39.48003602027893\n",
      "epoch_8eval后遍历dataloader用时7.95724892616272\n",
      "有更新, 最新的loss是33.77993979590747\n",
      "是否真的存进去了:  False\n",
      "epoch_9遍历dataloader用时38.97692584991455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:48:36,547] Trial 11 finished with value: 33.779267262574706 and parameters: {'optimizer': 'SGD', 'lr': 9.623416853269908e-05, 'hidden_dim': 42, 'batch_size': 34, 'num_layers': 1, 'patience': 10}. Best is trial 11 with value: 33.779267262574706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_9eval后遍历dataloader用时8.050135135650635\n",
      "有更新, 最新的loss是33.779267262574706\n",
      "是否真的存进去了:  False\n",
      "epoch_0遍历dataloader用时82.0165901184082\n",
      "epoch_0eval后遍历dataloader用时7.918859958648682\n",
      "有更新, 最新的loss是33.824370360482334\n",
      "是否真的存进去了:  False\n",
      "epoch_1遍历dataloader用时81.52878379821777\n",
      "epoch_1eval后遍历dataloader用时7.944138050079346\n",
      "有更新, 最新的loss是33.807115365093686\n",
      "是否真的存进去了:  False\n",
      "epoch_2遍历dataloader用时81.13580679893494\n",
      "epoch_2eval后遍历dataloader用时7.953685998916626\n",
      "有更新, 最新的loss是33.801654750746735\n",
      "是否真的存进去了:  False\n",
      "epoch_3遍历dataloader用时65.37120294570923\n",
      "epoch_3eval后遍历dataloader用时8.097318887710571\n",
      "有更新, 最新的loss是33.79646881123609\n",
      "是否真的存进去了:  False\n",
      "epoch_4遍历dataloader用时65.57032012939453\n",
      "epoch_4eval后遍历dataloader用时7.879073143005371\n",
      "有更新, 最新的loss是33.7829642887164\n",
      "是否真的存进去了:  False\n",
      "epoch_5遍历dataloader用时75.46710085868835\n",
      "epoch_5eval后遍历dataloader用时8.420695066452026\n",
      "有更新, 最新的loss是33.78157582658246\n",
      "是否真的存进去了:  False\n",
      "epoch_6遍历dataloader用时82.93755102157593\n",
      "epoch_6eval后遍历dataloader用时7.762089014053345\n",
      "有更新, 最新的loss是33.7808766219411\n",
      "是否真的存进去了:  False\n",
      "epoch_7遍历dataloader用时84.04229688644409\n",
      "epoch_7eval后遍历dataloader用时7.885947227478027\n",
      "有更新, 最新的loss是33.78053980101557\n",
      "是否真的存进去了:  False\n",
      "epoch_8遍历dataloader用时83.95625400543213\n",
      "epoch_8eval后遍历dataloader用时7.524735927581787\n",
      "epoch_9遍历dataloader用时85.69556403160095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:03:03,116] Trial 12 finished with value: 33.78053980101557 and parameters: {'optimizer': 'SGD', 'lr': 0.0002381793553615281, 'hidden_dim': 41, 'batch_size': 34, 'num_layers': 1, 'patience': 10}. Best is trial 11 with value: 33.779267262574706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_9eval后遍历dataloader用时7.405421018600464\n",
      "epoch_0遍历dataloader用时84.6364209651947\n",
      "epoch_0eval后遍历dataloader用时8.099303007125854\n",
      "有更新, 最新的loss是33.14671507284332\n",
      "是否真的存进去了:  False\n",
      "epoch_1遍历dataloader用时84.01660108566284\n",
      "epoch_1eval后遍历dataloader用时7.937386989593506\n",
      "有更新, 最新的loss是33.1456491356901\n",
      "是否真的存进去了:  False\n",
      "epoch_2遍历dataloader用时84.67566800117493\n",
      "epoch_2eval后遍历dataloader用时7.950069904327393\n",
      "epoch_3遍历dataloader用时83.85667610168457\n",
      "epoch_3eval后遍历dataloader用时7.983610153198242\n",
      "epoch_4遍历dataloader用时83.52186584472656\n",
      "epoch_4eval后遍历dataloader用时7.999112129211426\n",
      "epoch_5遍历dataloader用时83.26309823989868\n",
      "epoch_5eval后遍历dataloader用时7.912407875061035\n",
      "epoch_6遍历dataloader用时84.20109605789185\n",
      "epoch_6eval后遍历dataloader用时7.98016095161438\n",
      "epoch_7遍历dataloader用时83.99476194381714\n",
      "epoch_7eval后遍历dataloader用时8.00323486328125\n",
      "epoch_8遍历dataloader用时84.2220606803894\n",
      "epoch_8eval后遍历dataloader用时8.038411140441895\n",
      "epoch_9遍历dataloader用时83.1901650428772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:18:22,595] Trial 13 finished with value: 33.1456491356901 and parameters: {'optimizer': 'SGD', 'lr': 0.0005177713767570228, 'hidden_dim': 36, 'batch_size': 35, 'num_layers': 1, 'patience': 10}. Best is trial 13 with value: 33.1456491356901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_9eval后遍历dataloader用时7.965914011001587\n",
      "epoch_0遍历dataloader用时77.62720799446106\n",
      "epoch_0eval后遍历dataloader用时7.136147975921631\n",
      "有更新, 最新的loss是30.057184639214054\n",
      "是否真的存进去了:  False\n",
      "epoch_1遍历dataloader用时74.75176501274109\n",
      "epoch_1eval后遍历dataloader用时6.991328001022339\n",
      "epoch_2遍历dataloader用时77.28970098495483\n",
      "epoch_2eval后遍历dataloader用时7.176287889480591\n",
      "epoch_3遍历dataloader用时72.82161569595337\n",
      "epoch_3eval后遍历dataloader用时7.121739149093628\n",
      "epoch_4遍历dataloader用时38.875744104385376\n",
      "epoch_4eval后遍历dataloader用时7.066297769546509\n",
      "有更新, 最新的loss是30.052562837842935\n",
      "是否真的存进去了:  False\n",
      "epoch_5遍历dataloader用时51.5981502532959\n",
      "epoch_5eval后遍历dataloader用时7.13196587562561\n",
      "epoch_6遍历dataloader用时77.10945796966553\n",
      "epoch_6eval后遍历dataloader用时7.184481859207153\n",
      "有更新, 最新的loss是30.045704902811355\n",
      "是否真的存进去了:  False\n",
      "epoch_7遍历dataloader用时55.81962323188782\n",
      "epoch_7eval后遍历dataloader用时7.121373891830444\n",
      "epoch_8遍历dataloader用时74.61687994003296\n",
      "epoch_8eval后遍历dataloader用时7.167531967163086\n",
      "有更新, 最新的loss是30.03711635981817\n",
      "是否真的存进去了:  False\n",
      "epoch_9遍历dataloader用时76.9711081981659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:30:50,755] Trial 14 finished with value: 30.031629359653024 and parameters: {'optimizer': 'SGD', 'lr': 0.0016795332684630372, 'hidden_dim': 32, 'batch_size': 38, 'num_layers': 1, 'patience': 9}. Best is trial 14 with value: 30.031629359653024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_9eval后遍历dataloader用时6.541821002960205\n",
      "有更新, 最新的loss是30.031629359653024\n",
      "是否真的存进去了:  False\n",
      "epoch_0遍历dataloader用时81.43228816986084\n",
      "epoch_0eval后遍历dataloader用时7.703155040740967\n",
      "有更新, 最新的loss是31.427574337822517\n",
      "是否真的存进去了:  False\n",
      "epoch_1遍历dataloader用时80.9988899230957\n",
      "epoch_1eval后遍历dataloader用时7.588786840438843\n",
      "epoch_2遍历dataloader用时81.31915426254272\n",
      "epoch_2eval后遍历dataloader用时7.60837984085083\n",
      "epoch_3遍历dataloader用时81.14563775062561\n",
      "epoch_3eval后遍历dataloader用时7.619600057601929\n",
      "epoch_4遍历dataloader用时77.48486709594727\n",
      "epoch_4eval后遍历dataloader用时7.09769082069397\n",
      "有更新, 最新的loss是31.4264169524959\n",
      "是否真的存进去了:  False\n",
      "epoch_5遍历dataloader用时72.60696911811829\n",
      "epoch_5eval后遍历dataloader用时7.147017955780029\n",
      "epoch_6遍历dataloader用时77.1700689792633\n",
      "epoch_6eval后遍历dataloader用时7.116508960723877\n",
      "epoch_7遍历dataloader用时77.80033373832703\n",
      "epoch_7eval后遍历dataloader用时7.347854137420654\n",
      "有更新, 最新的loss是31.42538440357725\n",
      "是否真的存进去了:  False\n",
      "epoch_8遍历dataloader用时68.71738028526306\n",
      "epoch_8eval后遍历dataloader用时7.616121053695679\n",
      "有更新, 最新的loss是31.421712276251878\n",
      "是否真的存进去了:  False\n",
      "epoch_9遍历dataloader用时73.92934393882751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:44:57,837] Trial 15 finished with value: 31.420737926102333 and parameters: {'optimizer': 'SGD', 'lr': 0.001473581800458172, 'hidden_dim': 31, 'batch_size': 37, 'num_layers': 1, 'patience': 8}. Best is trial 14 with value: 30.031629359653024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_9eval后遍历dataloader用时7.588289976119995\n",
      "有更新, 最新的loss是31.420737926102333\n",
      "是否真的存进去了:  False\n",
      "epoch_0遍历dataloader用时88.5583291053772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:46:42,403] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0eval后遍历dataloader用时15.980772733688354\n",
      "epoch_0遍历dataloader用时77.36084365844727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:48:07,350] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0eval后遍历dataloader用时7.568697214126587\n",
      "epoch_0遍历dataloader用时63.97609305381775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:49:22,246] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0eval后遍历dataloader用时10.903244972229004\n",
      "有更新, 最新的loss是48.13574231674313\n",
      "是否真的存进去了:  False\n",
      "epoch_0遍历dataloader用时39.94445204734802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:50:07,721] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0eval后遍历dataloader用时5.5163938999176025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/dz6zsv052q319bqsbfdq06qm0000gn/T/ipykernel_88852/3032149754.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model_state = torch.load(\"best_model.pth\")\n",
      "/var/folders/m1/dz6zsv052q319bqsbfdq06qm0000gn/T/ipykernel_88852/3032149754.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.18215669691562653' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  submission.at[idx, 'value'] = pred_value\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 68\u001B[0m\n\u001B[1;32m     66\u001B[0m inputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(last_window, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32, requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     67\u001B[0m ig \u001B[38;5;241m=\u001B[39m IntegratedGradients(best_model)\n\u001B[0;32m---> 68\u001B[0m attributions, delta \u001B[38;5;241m=\u001B[39m ig\u001B[38;5;241m.\u001B[39mattribute(inputs, target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, return_convergence_delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     69\u001B[0m \u001B[38;5;66;03m# 绘制特征重要性图\u001B[39;00m\n\u001B[1;32m     70\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m5\u001B[39m))\n",
      "File \u001B[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/captum/log/__init__.py:42\u001B[0m, in \u001B[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:286\u001B[0m, in \u001B[0;36mIntegratedGradients.attribute\u001B[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001B[0m\n\u001B[1;32m    274\u001B[0m     attributions \u001B[38;5;241m=\u001B[39m _batch_attribution(\n\u001B[1;32m    275\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    276\u001B[0m         num_examples,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    283\u001B[0m         method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[1;32m    284\u001B[0m     )\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 286\u001B[0m     attributions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_attribute(\n\u001B[1;32m    287\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    288\u001B[0m         baselines\u001B[38;5;241m=\u001B[39mbaselines,\n\u001B[1;32m    289\u001B[0m         target\u001B[38;5;241m=\u001B[39mtarget,\n\u001B[1;32m    290\u001B[0m         additional_forward_args\u001B[38;5;241m=\u001B[39madditional_forward_args,\n\u001B[1;32m    291\u001B[0m         n_steps\u001B[38;5;241m=\u001B[39mn_steps,\n\u001B[1;32m    292\u001B[0m         method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[1;32m    293\u001B[0m     )\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_convergence_delta:\n\u001B[1;32m    296\u001B[0m     start_point, end_point \u001B[38;5;241m=\u001B[39m baselines, inputs\n",
      "File \u001B[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:360\u001B[0m, in \u001B[0;36mIntegratedGradients._attribute\u001B[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001B[0m\n\u001B[1;32m    351\u001B[0m grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_func(\n\u001B[1;32m    352\u001B[0m     forward_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_func,\n\u001B[1;32m    353\u001B[0m     inputs\u001B[38;5;241m=\u001B[39mscaled_features_tpl,\n\u001B[1;32m    354\u001B[0m     target_ind\u001B[38;5;241m=\u001B[39mexpanded_target,\n\u001B[1;32m    355\u001B[0m     additional_forward_args\u001B[38;5;241m=\u001B[39minput_additional_args,\n\u001B[1;32m    356\u001B[0m )\n\u001B[1;32m    358\u001B[0m \u001B[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001B[39;00m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001B[39;00m\n\u001B[0;32m--> 360\u001B[0m scaled_grads \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    361\u001B[0m     grad\u001B[38;5;241m.\u001B[39mcontiguous()\u001B[38;5;241m.\u001B[39mview(n_steps, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(step_sizes)\u001B[38;5;241m.\u001B[39mview(n_steps, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(grad\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    363\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m grad \u001B[38;5;129;01min\u001B[39;00m grads\n\u001B[1;32m    364\u001B[0m ]\n\u001B[1;32m    366\u001B[0m \u001B[38;5;66;03m# aggregates across all steps for each tensor in the input tuple\u001B[39;00m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;66;03m# total_grads has the same dimensionality as inputs\u001B[39;00m\n\u001B[1;32m    368\u001B[0m total_grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\n\u001B[1;32m    369\u001B[0m     _reshape_and_sum(\n\u001B[1;32m    370\u001B[0m         scaled_grad, n_steps, grad\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_steps, grad\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m    371\u001B[0m     )\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (scaled_grad, grad) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(scaled_grads, grads)\n\u001B[1;32m    373\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:362\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    351\u001B[0m grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_func(\n\u001B[1;32m    352\u001B[0m     forward_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_func,\n\u001B[1;32m    353\u001B[0m     inputs\u001B[38;5;241m=\u001B[39mscaled_features_tpl,\n\u001B[1;32m    354\u001B[0m     target_ind\u001B[38;5;241m=\u001B[39mexpanded_target,\n\u001B[1;32m    355\u001B[0m     additional_forward_args\u001B[38;5;241m=\u001B[39minput_additional_args,\n\u001B[1;32m    356\u001B[0m )\n\u001B[1;32m    358\u001B[0m \u001B[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001B[39;00m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001B[39;00m\n\u001B[1;32m    360\u001B[0m scaled_grads \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    361\u001B[0m     grad\u001B[38;5;241m.\u001B[39mcontiguous()\u001B[38;5;241m.\u001B[39mview(n_steps, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 362\u001B[0m     \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(step_sizes)\u001B[38;5;241m.\u001B[39mview(n_steps, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(grad\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    363\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m grad \u001B[38;5;129;01min\u001B[39;00m grads\n\u001B[1;32m    364\u001B[0m ]\n\u001B[1;32m    366\u001B[0m \u001B[38;5;66;03m# aggregates across all steps for each tensor in the input tuple\u001B[39;00m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;66;03m# total_grads has the same dimensionality as inputs\u001B[39;00m\n\u001B[1;32m    368\u001B[0m total_grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\n\u001B[1;32m    369\u001B[0m     _reshape_and_sum(\n\u001B[1;32m    370\u001B[0m         scaled_grad, n_steps, grad\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_steps, grad\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m    371\u001B[0m     )\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (scaled_grad, grad) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(scaled_grads, grads)\n\u001B[1;32m    373\u001B[0m )\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead."
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
